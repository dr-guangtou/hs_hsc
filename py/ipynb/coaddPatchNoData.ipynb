{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['copy', 'Polygon']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import copy\n",
    "import os \n",
    "import argparse\n",
    "import numpy as np \n",
    "\n",
    "from astropy.io import fits \n",
    "from astropy    import wcs \n",
    "\n",
    "import lsst.daf.persistence   as dafPersist\n",
    "import lsst.afw.coord         as afwCoord\n",
    "import lsst.afw.image         as afwImage\n",
    "import lsst.afw.geom          as afwGeom\n",
    "import lsst.afw.table         as afwTable\n",
    "\n",
    "# Matplotlib default settings\n",
    "import matplotlib as mpl \n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams['figure.figsize'] = 12, 10\n",
    "mpl.rcParams['xtick.major.size'] = 8.0\n",
    "mpl.rcParams['xtick.major.width'] = 1.5\n",
    "mpl.rcParams['xtick.minor.size'] = 4.0\n",
    "mpl.rcParams['xtick.minor.width'] = 1.5\n",
    "mpl.rcParams['ytick.major.size'] = 8.0\n",
    "mpl.rcParams['ytick.major.width'] = 1.5\n",
    "mpl.rcParams['ytick.minor.size'] = 4.0\n",
    "mpl.rcParams['ytick.minor.width'] = 1.5\n",
    "mpl.rc('axes', linewidth=2)\n",
    "\n",
    "# Shapely related imports \n",
    "from shapely.geometry import MultiPolygon, Point\n",
    "from shapely.geometry import Polygon, LineString\n",
    "from shapely          import wkb \n",
    "from shapely.ops      import cascaded_union \n",
    "\n",
    "from scipy import ndimage\n",
    "from skimage.measure import find_contours, approximate_polygon    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def showHscMask(coords, large=None, title='No Data Mask Plane', \n",
    "                pngName=None):\n",
    "    \n",
    "    from matplotlib.patches import Polygon as mpPoly\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 10), dpi=120)\n",
    "\n",
    "    ax = fig.add_subplot(111)\n",
    "    fontsize = 14\n",
    "    ax.minorticks_on()\n",
    "\n",
    "    for tick in ax.xaxis.get_major_ticks():\n",
    "        tick.label1.set_fontsize(fontsize)\n",
    "    for tick in ax.yaxis.get_major_ticks():\n",
    "        tick.label1.set_fontsize(fontsize)\n",
    "        \n",
    "    # Set title\n",
    "    ax.set_title(title, fontsize=25, fontweight='bold')\n",
    "    ax.title.set_position((0.5,1.01))\n",
    "\n",
    "    # Outline all the mask regions\n",
    "    for raDec in coords:\n",
    "        ax.plot(raDec[:, 1], raDec[:, 0], '-r', linewidth=1.5)\n",
    "    \n",
    "    # Using polygon to highlight all the large ones\n",
    "    if large is not None:\n",
    "        for raDec in large:\n",
    "            ax.plot(raDec[:, 1], raDec[:, 0], '-b', linewidth=2.0)\n",
    "                \n",
    "    fig.subplots_adjust(hspace=0.1, wspace=0.1,\n",
    "                        top=0.95, right=0.95)\n",
    "    \n",
    "    if pngName is not None:     \n",
    "        fig.savefig(pngName)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imgAddNoise(im, gaussian, factor): \n",
    "    \n",
    "    im = ndimage.gaussian_filter(im, gaussian)\n",
    "    im += factor * np.random.random(im.shape)\n",
    "    \n",
    "    return im "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPixelRaDec(wcs, xx, yy): \n",
    "    \n",
    "    coord = wcs.pixelToSky(xx, yy).toIcrs()\n",
    "        \n",
    "    ra  = coord.getRa().asDegrees()\n",
    "    dec = coord.getDec().asDegrees()\n",
    "    \n",
    "    return ra, dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def polySaveWkb(poly, wkbName):\n",
    "\n",
    "    polyWkb = wkb.dumps(poly)\n",
    "\n",
    "    wkbFile = open(wkbName, 'w')\n",
    "    wkbFile.write(polyWkb.encode('hex'))\n",
    "    wkbFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the Polygon region into a DS9 .reg file\n",
    "def getPolyLine(polyCoords):\n",
    "\n",
    "    coordShow = map(lambda x: str(x[0]) + ' ' + str(x[1]) + ' ', polyCoords)\n",
    "\n",
    "    # The format for Polygon in DS9 is:\n",
    "    # Usage: polygon x1 y1 x2 y2 x3 y3 ...\n",
    "    polyLine = 'polygon '\n",
    "    for p in coordShow:\n",
    "        polyLine += p\n",
    "\n",
    "    polyLine += '\\n'\n",
    "\n",
    "    return polyLine\n",
    "\n",
    "# !!! Make sure that the Polygon is simple\n",
    "def polySaveReg(poly, regName, listPoly=False, color='blue'):\n",
    "\n",
    "    # DS9 region file header\n",
    "    head1 = '# Region file format: DS9 version 4.1\\n'\n",
    "    head2 = 'global color=%s width=2\\n' % color\n",
    "    head3 = 'icrs\\n'\n",
    "    # Open the output file and write the header\n",
    "    regFile = open(regName, 'w')\n",
    "    regFile.write(head1)\n",
    "    regFile.write(head2)\n",
    "    regFile.write(head3)\n",
    "\n",
    "    if listPoly:\n",
    "        #for pp in poly:\n",
    "        for i in range(len(poly)):\n",
    "            pp = poly[i]\n",
    "            print i\n",
    "            if pp.geom_type is \"Polygon\":\n",
    "            # Get the coordinates for every point in the polygon\n",
    "                polyCoords = pp.boundary.coords[:]\n",
    "                polyLine = getPolyLine(polyCoords)\n",
    "                regFile.write(polyLine)\n",
    "            elif pp.geom_type is \"MultiPolygon\":\n",
    "                for mm in pp.geoms: \n",
    "                    polyCoords = mm.boundary.coords[:]\n",
    "                    polyLine = getPolyLine(polyCoords)\n",
    "                    regFile.write(polyLine)\n",
    "    else:\n",
    "        if poly.geom_type is \"Polygon\":\n",
    "            polyCoords = poly.boundary.coords[:]\n",
    "            polyLine = getPolyLine(polyCoords)\n",
    "            regFile.write(polyLine)\n",
    "        elif poly.geom_type is \"MultiPolygon\":\n",
    "            for mm in pply.geoms: \n",
    "                polyCoords = mm.boundary.coords[:]\n",
    "                polyLine = getPolyLine(polyCoords)\n",
    "                regFile.write(polyLine)            \n",
    "\n",
    "    regFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def coaddPatchNoData(rootDir, tract, patch, filter, prefix='hsc_coadd', \n",
    "                     savePNG=True, verbose=True, tolerence=4, \n",
    "                     minArea=10000): \n",
    "    \n",
    "    # Make a butler and specify the dataID \n",
    "    butler = dafPersist.Butler(rootDir)\n",
    "    dataId = {'tract':tract, 'patch':patch, 'filter':filter}\n",
    "    \n",
    "    # Get the name of the input fits image\n",
    "    if rootDir[-1] is '/': \n",
    "        fitsName = rootDir + 'deepCoadd/' + filter + '/' + str(tract).strip() + '/' + patch + '.fits'\n",
    "    else: \n",
    "        fitsName = rootDir + '/deepCoadd/' + filter + '/' + str(tract).strip() + '/' + patch + '.fits'\n",
    "    if not os.path.isfile(fitsName): \n",
    "        raise Exception('Can not find the input fits image: %s' % fitsName)\n",
    "    # Read in the original image and get the wcs \n",
    "    # TODO: This is not perfect\n",
    "    hduList = fits.open(fitsName)\n",
    "    header = hduList[1].header \n",
    "    imgWcs = wcs.WCS(header)\n",
    "        \n",
    "    # Get the name of the wkb and deg file\n",
    "    strTractPatch = (str(tract).strip() + '_' + patch + '_' + filter)\n",
    "    ## For all the accepted regions \n",
    "    noDataAllWkb = prefix + '_' + strTractPatch + '_nodata_all.wkb'\n",
    "    noDataAllReg = prefix + '_' + strTractPatch + '_nodata_all.reg'\n",
    "    ## For all the big mask regions \n",
    "    noDataBigWkb = prefix + '_' + strTractPatch + '_nodata_big.wkb'\n",
    "    noDataBigReg = prefix + '_' + strTractPatch + '_nodata_big.reg'    \n",
    "    \n",
    "    # Get the name of the png file\n",
    "    titlePng = prefix + strTractPatch + '_NODATA'\n",
    "    noDataPng = prefix + '_' + strTractPatch + '_nodata.png'\n",
    "    \n",
    "    if verbose: \n",
    "        print \"## Reading Fits Image: %s\" % fitsName\n",
    "        \n",
    "    # Get the exposure from the butler \n",
    "    calExp = butler.get('deepCoadd', dataId, immediate=True)\n",
    "    \n",
    "    # Get the object for mask plane \n",
    "    mskImg = calExp.getMaskedImage().getMask() \n",
    "    \n",
    "    # Extract the NO_DATA plane \n",
    "    # TODO: NO_DATA is not a system mask, maybe should use INTRP later\n",
    "    noData = copy.deepcopy(mskImg)\n",
    "    noData &= noData.getPlaneBitMask('NO_DATA')\n",
    "    # Return the mask image array \n",
    "    noDataArr = noData.getArray()\n",
    "    \n",
    "    # Set all masked pixels to be 1\n",
    "    noDataArr /= 256\n",
    "    # Pad the 2-D array by a little \n",
    "    noDataArr = np.lib.pad(noDataArr, ((1, 1), (1, 1)), 'constant', constant_values=0)    \n",
    "    \n",
    "    # Try a very different approach: Using the find_contours and \n",
    "    # approximate_polygon methods from scikit-images package\n",
    "    maskShapes = []  # For all the accepted mask regions \n",
    "    maskCoords = []  # For the \"corner\" coordinates of these regions\n",
    "    maskAreas  = []  # The sizes of all regions\n",
    "    \n",
    "    # Only find the 0-level contour \n",
    "    contoursAll = find_contours(noDataArr, 0)\n",
    "    if verbose: \n",
    "        print \"### %d contours have been detected\" % len(contoursAll)\n",
    "    for maskContour in contoursAll:\n",
    "        # Approximate one extracted contour into a polygon\n",
    "        # tolerance decides the accuracy of the polygon, hence \n",
    "        # the number of coords for each polygon.  \n",
    "        # Using large tolerance also means smaller number of final \n",
    "        # polygons\n",
    "        contourCoords = approximate_polygon(maskContour, tolerance=tolerence)\n",
    "        # Convert these coordinates into (RA, DEC) using the WCS information \n",
    "        contourSkyCoords = map(lambda x: [x[1], x[0]], contourCoords)\n",
    "        contourRaDec     = imgWcs.wcs_pix2world(contourSkyCoords, 1)\n",
    "        # Require that any useful region must be at least an triangular \n",
    "        if len(contourCoords) >= 3: \n",
    "            # Form a lineString using these coordinates \n",
    "            maskLine = LineString(contourRaDec)\n",
    "            # Check if the lineString is valid and simple, so can be used \n",
    "            # to form a closed and simple polygon\n",
    "            if maskLine.is_valid and maskLine.is_simple: \n",
    "                contourPoly = Polygon(contourRaDec)\n",
    "                maskShapes.append(contourPoly)\n",
    "                maskCoords.append(contourRaDec)\n",
    "                maskAreas.append(Polygon(contourCoords).area)\n",
    "                \n",
    "    if verbose: \n",
    "        print \"### %d regions are useful\" % len(maskAreas)\n",
    "    # Save all the masked regions to a .reg file \n",
    "    polySaveReg(maskShapes, noDataAllReg, listPoly=True)\n",
    "    # Also create a MultiPolygon object, and save a .wkb file \n",
    "    maskAll = cascaded_union(maskShapes)\n",
    "    polySaveWkb(maskAll, noDataAllWkb)\n",
    "    \n",
    "    # Isolate the large ones\n",
    "    maskBigList = np.array(maskShapes)[np.where(np.array(maskAreas) > minArea)]\n",
    "    maskBigList = map(lambda x: x, maskBigList)\n",
    "    coordBigList = np.array(maskCoords)[np.where(np.array(maskAreas) > minArea)]\n",
    "    nBig = len(maskBigList)\n",
    "    if nBig > 0: \n",
    "        if verbose: \n",
    "            print \"### %d regions are larger than the minimum mask sizes\" % nBig\n",
    "        # Save all the masked regions to a .reg file \n",
    "        polySaveReg(maskBigList, noDataBigReg, listPoly=True)\n",
    "        # Also create a MultiPolygon object, and save a .wkb file \n",
    "        maskBig = cascaded_union(maskBigList)\n",
    "        polySaveWkb(maskBig, noDataBigWkb)  \n",
    "    else: \n",
    "        maskBig = None\n",
    "        if verbose: \n",
    "            print \"### No region is larger than the minimum mask sizes\"\n",
    "        \n",
    "    if savePNG:\n",
    "        showHscMask(maskCoords, large=coordBigList, title=titlePng, pngName=noDataPng)\n",
    "                \n",
    "    return maskAll, maskBig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Example \n",
    "\n",
    "rootDir = '/lustre/Subaru/SSP/rerun/yasuda/SSP3.4.1_20141224/'\n",
    "tract   = 8280\n",
    "patch   = '2,2' \n",
    "filter  = 'HSC-I'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Reading Fits Image: /lustre/Subaru/SSP/rerun/yasuda/SSP3.4.1_20141224/deepCoadd/HSC-I/8280/2,2.fits\n",
      "### 314 contours have been detected\n",
      "### 109 regions are useful\n",
      "### 2 regions are larger than the minimum mask sizes\n"
     ]
    }
   ],
   "source": [
    "maskAll, maskBig = coaddPatchNoData(rootDir, tract, patch, filter, prefix='hsc_coadd', \n",
    "                                    savePNG=True, verbose=True, tolerence=4, minArea=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def listAllImages(rootDir, filter):\n",
    "\n",
    "    import glob\n",
    "\n",
    "    if rootDir[-1] is '/':\n",
    "        searchDir = rootDir + 'deepCoadd/' + filter.upper() + '/*/*.fits'\n",
    "    else:\n",
    "        searchDir = rootDir + '/deepCoadd/' + filter.upper() + '/*/*.fits'\n",
    "\n",
    "    return map(lambda x: x, glob.glob(searchDir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def batchPatchNoData(rootDir, filter='HSC-I', prefix='hsc_coadd'): \n",
    "    \n",
    "    # Get the list of coadded images in the direction \n",
    "    imgList = listAllImages(rootDir, filter) \n",
    "    imgList = imgList[0:3] ### Test\n",
    "    \n",
    "    # Get the list of tract and patch for these images \n",
    "    tract = map(lambda x: int(x.split('/')[-2]), imgList)\n",
    "    patch = map(lambda x: x.split('/')[-1].split('.')[0], imgList)\n",
    "    \n",
    "    results = map(lambda x, y: coaddPatchNoData(rootDir, x, y, filter, \n",
    "                                prefix=prefix, savePNG=True, verbose=True, tolerence=4,\n",
    "                                minArea=10000), tract, patch)\n",
    "    allList = map(lambda x: x[0], results)\n",
    "    bigList = map(lambda x: x[1], results)\n",
    "    \n",
    "    allUse = [] \n",
    "    for ss in allList: \n",
    "        if ss is not None: \n",
    "            allUse.append(ss)\n",
    "    bigUse = [] \n",
    "    for tt in bigList: \n",
    "        if tt is not None: \n",
    "            bigUse.append(tt)\n",
    "            \n",
    "    # Make a cascaded union of them \n",
    "    allComb = cascaded_union(allUse)\n",
    "    bigComb = cascaded_union(bigUse)\n",
    "    \n",
    "    # Save these polygons as a .wkb file \n",
    "    polySaveWkb(allComb, prefix + '_' + filter + '_nodata_all_combined.wkb')\n",
    "    polySaveWkb(bigComb, prefix + '_' + filter + '_nodata_big_combined.wkb')\n",
    "    \n",
    "    # Break them down into list \n",
    "    ## ALL \n",
    "    if len(allUse) > 0: \n",
    "        polySaveReg(allUse, prefix + '_' + filter + '_nodata_all_combined.reg', \n",
    "                    listPoly=True, color='red')\n",
    "    ## BIG\n",
    "    if len(bigUse) > 0:\n",
    "        polySaveReg(bigUse, prefix + '_' + filter + '_nodata_big_combined.reg', \n",
    "                    listPoly=True, color='blue')\n",
    "    \n",
    "    return allComb, bigComb"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Example of batch mode \n",
    "rootDir = '/lustre/Subaru/SSP/rerun/yasuda/SSP3.4.1_cosmos_setWeight'\n",
    "prefix  = 'ssp341_cosmos'\n",
    "filter  = 'HSC-I'\n",
    "\n",
    "allComb, bigComb = batchPatchNoData(rootDir, filter=filter, prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read a .wkb file into a Polygon shape\n",
    "def polyReadWkb(wkbName, load=True):\n",
    "\n",
    "    wkbFile = open(wkbName, 'r')\n",
    "    polyWkb = wkbFile.read().decode('hex')\n",
    "    wkbFile.close()\n",
    "\n",
    "    if load is True:\n",
    "        return wkb.loads(polyWkb)\n",
    "    else:\n",
    "        return polyWkb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test1 = polyReadWkb('/home/song/work/early/ssp341_wide_nodata/ssp341_wide_9451_2,8_HSC-G_nodata_all.wkb').geoms[:]\n",
    "test2 = polyReadWkb('/home/song/work/early/ssp341_wide_nodata/ssp341_wide_9451_2,6_HSC-G_nodata_all.wkb').geoms[:]\n",
    "test3 = polyReadWkb('/home/song/work/early/ssp341_wide_nodata/ssp341_wide_9451_2,7_HSC-G_nodata_all.wkb').geoms[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#files = ['/home/song/work/early/ssp341_wide_nodata/ssp341_wide_9451_2,8_HSC-G_nodata_all.wkb', \n",
    "#         '/home/song/work/early/ssp341_wide_nodata/ssp341_wide_9451_2,7_HSC-G_nodata_all.wkb', \n",
    "#         '/home/song/work/early/ssp341_wide_nodata/ssp341_wide_9451_2,6_HSC-G_nodata_all.wkb']\n",
    "files = ['/home/song/work/early/ssp341_cosmos_nodata/ssp341_cosmos_0_HSC-G_nodata_all_wkb.wkb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = []\n",
    "for f in files: \n",
    "    geoms = polyReadWkb(f).geoms[:]\n",
    "    for g in geoms: \n",
    "        temp.append(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = cascaded_union(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(150.93634600593458, 2.203149695207256),\n",
       " (150.94545041307933, 2.202631198051483),\n",
       " (150.97103650018613, 2.2022429412464475),\n",
       " (150.9451698378152, 2.2018847768753727),\n",
       " (150.9367652097121, 2.201376317796325),\n",
       " (150.93335698855435, 2.2017515501287455),\n",
       " (150.92924439045134, 2.2018662548760792),\n",
       " (150.9156612029758, 2.202041468769308),\n",
       " (150.9138403690229, 2.2022757896242977),\n",
       " (150.92152445243738, 2.202524387128262),\n",
       " (150.92154461993135, 2.202598124755066),\n",
       " (150.92699955925343, 2.202701519235631),\n",
       " (150.92943552884753, 2.2027803283698066),\n",
       " (150.9307428779161, 2.2027795881924677),\n",
       " (150.93074322960956, 2.202772477834623),\n",
       " (150.93349767287359, 2.2028246863402936),\n",
       " (150.93634600593458, 2.203149695207256)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[1].boundary.coords[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask = polyReadWkb(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = mask.geoms[2672].boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ra, dec = 150.939, 2.2028"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.contains(Point(ra, dec))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
